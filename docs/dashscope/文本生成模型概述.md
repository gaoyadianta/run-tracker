文本生成模型能够基于输入的提示词（Prompt）创作出逻辑清晰、连贯的文本。

文本生成模型所需的输入可以是简单的关键词、一句话概述或是更复杂的指令和上下文信息。模型通过分析海量数据学习语言模式，广泛应用于：

内容创作：生成新闻报道、商品介绍及短视频脚本。

客户服务：驱动聊天机器人提供全天候支持，解答常见问题。

文本翻译：实现跨语言的快速精准转换。

摘要生成：提炼长文、报告及邮件的核心内容。

法律文档编写：生成合同模板、法律意见书的基础框架。

更多示例可以参考文本生成样例。

模型选型建议
服务地域
阿里云百炼提供北京地域和新加坡地域的模型服务，各地域的API-Key不同，选择邻近地域调用可降低网络延迟。

通用模型
通义千问Max、通义千问Plus 和通义千问Flash 均已升级至Qwen3系列，并兼容OpenAI调用方式，适用于智能客服、文本创作、内容润色以及摘要总结等多种场景。

通义千问Plus：在效果、速度和成本上表现均衡，是多数场景的推荐选择。

通义千问Max ：通义千问系列效果最好的模型，适合处理复杂、多步骤任务。

通义千问Flash ：通义千问系列速度最快、成本极低的模型，适用于执行简单任务。

特定场景模型
针对明确的业务需求，阿里云百炼提供多种专用优化模型，覆盖代码能力、长上下文、翻译、数据挖掘、法律、意图理解、角色扮演、深入研究等领域。

多模态模型
通义千问VL（文+图->文）：具备图像理解能力，支持光学字符识别（OCR）、视觉推理和图文理解等任务。

通义千问Omni（全模态-> 文+音）：支持视频、音频、图片、文本等多种数据输入，生成文本和语音输出，以应对跨模态复杂任务。

语音识别模型（音->文）：识别并转写音频中的语音内容，支持中文（含粤语等各种方言）、英文、日语、韩语等。

第三方模型
阿里云百炼支持 DeepSeek、Kimi、GLM等众多知名的第三方大语言模型，完整模型列表请参考文本生成-第三方模型。

核心概念
文本生成模型的输入为提示词（Prompt），它由一个或多个消息（Message）对象构成。每条消息由角色（Role）和内容（Content）组成，具体为：

系统消息（System Message）：设定模型扮演的角色或遵循的指令。若不指定，默认为"You are a helpful assistant"。

用户消息（User Message）：用户向模型提出的问题或输入的指令。

助手消息（Assistant Message）：模型的回复内容。

调用模型时，需构造一个由上述消息对象构成的数组messages。一个典型的请求通常由一条定义行为准则的 system 消息和一条用户提指令的 user 消息组成。

system消息是可选的，但建议使用它来设定模型的角色和行为准则，以获得更稳定、一致的输出。
 
[
    {"role": "system", "content": "你是一个有帮助的助手，需要提供精准、高效且富有洞察力的回应，随时准备协助用户处理各种任务与问题。"},
    {"role": "user", "content": "你是谁？"}
]
输出的响应对象中会包含模型回复的assistant消息。

 
{
    "role": "assistant",
    "content": "你好！我是Qwen，是阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字、进行逻辑推理、编程等。我能够理解并生成多种语言，支持多轮对话和复杂任务处理。如果你有任何需要帮助的地方，尽管告诉我！"
}
快速开始
API 使用前提：已获取与配置 API Key并完成配置API Key到环境变量。如果通过SDK调用，需要安装 OpenAI 或 DashScope SDK。

运行下方代码，开始与 qwen-plus 模型对话。如需获得更高质量的生成结果，可参考深度思考。

OpenAI兼容DashScope
PythonJavaNode.jsGoC#（HTTP）PHP（HTTP）curl
 
import os
from openai import OpenAI

try:
    client = OpenAI(
        # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
        # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key="sk-xxx",
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )

    completion = client.chat.completions.create(
        # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
        model="qwen-plus",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "你是谁？"},
        ],
    )
    print(completion.choices[0].message.content)
    # 如需查看完整响应，请取消下列注释
    # print(completion.model_dump_json())
except Exception as e:
    print(f"错误信息：{e}")
    print("请参考文档：https://help.aliyun.com/zh/model-studio/developer-reference/error-code")
返回结果
 
我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！
图像、视频数据处理
多模态模型支持处理图像、视频等非文本数据，可用于视觉问答、事件检测等任务。其调用方式与纯文本模型主要有以下不同：

用户消息（user message）的构造方式：多模态模型的用户消息不仅包含文本，还包含图片、音频等多模态信息。

DashScope SDK接口：使用 DashScope Python SDK 时，需调用 MultiModalConversation 接口；使用DashScope Java SDK 时，需调用 MultiModalConversation 类。

图片、视频文件限制请参见视觉理解。
OpenAI兼容DashScope
PythonNode.jscurl
 
from openai import OpenAI
import os

client = OpenAI(
    # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key="sk-xxx"
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)
messages = [
    {
        "role": "user",
        "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20251031/ownrof/f26d201b1e3f4e62ab4a1fc82dd5c9bb.png"
                    },
                },
            {"type": "text", "text": "请问图片展现了有哪些商品？"},
        ],
    }
]
completion = client.chat.completions.create(
    model="qwen3-vl-plus",  # 可按需更换为其它多模态模型，并修改相应的 messages
    messages=messages,
)
print(completion.choices[0].message.content)
异步调用模型
调用异步接口，可有效提升高并发请求的处理效率。

OpenAI兼容DashScope
PythonJava
 
import os
import asyncio
from openai import AsyncOpenAI
import platform

# 创建异步客户端实例
client = AsyncOpenAI(
    # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
    # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key="sk-xxx",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# 定义异步任务列表
async def task(question):
    print(f"发送问题: {question}")
    response = await client.chat.completions.create(
        messages=[
            {"role": "system", "content": "You are a helpful assistant." },
            {"role": "user", "content": question}
        ],
        model="qwen-plus",  # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
    )
    print(f"模型回复: {response.choices[0].message.content}")

# 主异步函数
async def main():
    questions = ["你是谁？", "你会什么？", "天气怎么样？"]
    tasks = [task(q) for q in questions]
    await asyncio.gather(*tasks)

if __name__ == '__main__':
    # 设置事件循环策略
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    # 运行主协程
    asyncio.run(main(), debug=False)
    
返回结果
由于调用是异步的，响应的返回顺序可能与示例不同。
 
发送问题: 你是谁？
发送问题: 你会什么？
发送问题: 天气怎么样？
模型回复: 你好！我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助你回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。如果你有任何问题或需要帮助，欢迎随时告诉我！
模型回复: 您好！我目前无法实时获取天气信息。您可以告诉我您所在的城市或地区，我会尽力为您提供一些通用的天气建议或信息。或者您也可以使用天气应用查看实时天气情况。
模型回复: 我会很多技能，比如：

1. **回答问题**：无论是学术问题、生活常识还是专业知识，我都可以尝试帮你解答。
2. **创作文字**：我可以写故事、公文、邮件、剧本等各类文本。
3. **逻辑推理**：我可以帮助你解决一些逻辑推理问题，比如数学题、谜语等。
4. **编程**：我可以提供编程帮助，包括代码编写、调试和优化。
5. **多语言支持**：我支持多种语言，包括但不限于中文、英文、法语、西班牙语等。
6. **观点表达**：我可以为你提供一些观点和建议，帮助你做出决策。
7. **玩游戏**：我们可以一起玩文字游戏，比如猜谜语、成语接龙等。

如果你有任何具体的需求或问题，欢迎告诉我，我会尽力帮助你！
应用于生产环境
构建高质量的上下文
向大模型直接输入大量原始数据，会因上下文容量的限制导致成本增加与效果下降。上下文工程（Context Engineering）通过动态加载精准知识，显著提升生成质量与效率。核心技术包括：

提示词工程（Prompt Engineering）：通过设计和优化文本指令（Prompt），可以更精确地引导模型，使其输出更符合预期的结果。若想了解更多，可参考文生文Prompt指南、阿里云百炼 提示词模板页面。

检索增强生成（RAG）：适用于需要模型依据外部知识库（例如产品文档或技术手册）来回答问题的场景。

工具调用（Tool）：允许模型获取实时信息（如查询天气、路况）或完成特定操作（如调用API、发送邮件）。

记忆机制（Memory）：为模型建立长短期记忆，使其能够理解连续对话的历史信息。

若想系统了解，可参考阿里云大模型高级工程师ACP认证课程。

控制回复多样性
temperature 和 top_p用于控制生成文本的多样性。数值越高，内容越多样，数值越低，内容越确定。为准确评估参数效果，建议每次只调整一个。

temperature：范围 [0, 2)。侧重调整随机性。

top_p：范围 [0, 1]。通过概率阈值筛选回复。

以下示例将展示不同参数设置对生成内容的影响。输入提示词为：“写一个三句话的短故事，主角是一只猫和一束阳光。”

高多样性（示例temperature=0.9）：适用于需要创意、想象力和新颖表达的场景，如创意写作、头脑风暴或市场营销文案。

 
阳光斜斜地切进窗台，橘猫蹑手蹑脚走近那块发光的方砖，绒毛瞬间被染成熔化的蜜糖。  
它伸出前爪轻拍光斑，却像踩进温热的池水般陷了进去，整片阳光顺着肉垫汩汩漫上脊背。  
午后忽然变得很重——猫儿蜷在流动的金砂里，听见时光在呼噜声中轻轻融化。
高确定性（示例temperature=0.1）：适用于要求内容准确、严谨和可预测的场景，如事实问答、代码生成或法律文本。

 
午后，一只老猫蜷在窗台，数着光斑打盹。  
阳光轻轻跃过它斑驳的脊背，像在翻阅一本旧相册。  
尘埃浮起又落下，仿佛时光低语：你曾年轻，我也炽热。
原理介绍

不同场景的参数配置示例

更多功能
上文介绍了基础的交互方式。针对更复杂的场景，可参考：

多轮对话：适用于追问、信息采集等需要连续交流的场景。

流式输出：适用于聊天机器人、实时代码生成等需要即时响应的场景，可以提升用户体验，并避免因响应时间过长导致的超时。

深度思考：适用于复杂推理、策略分析等需要更高质量、更具条理的深度回答的场景。

结构化输出：当需要模型按稳定的 JSON 格式回复，以便于程序调用或数据解析时使用。

前缀续写：适用于代码补全、长文写作等需要模型接续已有文本的场景。

API 参考
模型调用的完整参数列表，请参考 OpenAI 兼容 API 参考和DashScope API 参考。

常见问题
Q：通义千问 API 为何无法分析网页链接？
A：通义千问 API 本身不具备直接访问和解析网页链接的能力，可以通过Function Calling、MCP等功能，或结合 Python 的 Beautiful Soup 等网页抓取工具读取网页信息。

Q：网页端通义千问和通义千问 API 的回复为什么不一致？
A：网页端通义千问在通义千问 API 的基础上做了额外的工程优化，因此可以达到解析网页、联网搜索、画图、制作 PPT等功能，这些本身并不属于大模型 API 的能力，可以通过联网搜索、Function Calling、MCP等功能优化模型的效果。

Q：如何处理模型超时的情况？
A：使用流式输出可避免超时。

非流式调用若超过 300 秒未完成，服务将中断请求，但返回已生成的内容，且不再报超时错误。此时响应头将包含x-dashscope-partialresponse: true，表示返回的是超时前的部分结果。

支持该机制的模型如下：

支持的模型

若无法获取响应头参数（例如通过 SDK 调用），可通过 finish_reason字段辅助判断，若为null，表示生成内容不完整（但不一定是触发了超时）。
大模型可续写不完整的内容，详情请参见：基于不完整输出进行续写。

Java SDK 暂不支持前缀续写功能。
Q：模型能直接生成 Word、Excel、PDF 或 PPT 格式的文件吗？
A：不能。阿里云百炼的文本生成模型仅输出纯文本内容。您需要通过代码或使用第三方库将文本转换为所需格式，或通过阿里云百炼PPT自动生成应用、网页端通义千问等方式进行生成。